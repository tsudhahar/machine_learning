{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Reading in the Kaggle data and adding features\n",
    "2. Using a **`Pipeline`** for proper cross-validation\n",
    "3. Combining **`GridSearchCV`** with **`Pipeline`**\n",
    "4. Efficiently searching for tuning parameters using **`RandomizedSearchCV`**\n",
    "5. Adding features to a document-term matrix (using SciPy)\n",
    "6. Adding features to a document-term matrix (using **`FeatureUnion`**)\n",
    "7. Ensembling models\n",
    "8. Locating groups of similar cuisines\n",
    "9. Model stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for Python 2: use print only as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading in the Kaggle data and adding features\n",
    "\n",
    "- Our goal is to predict the **cuisine** of a recipe, given its **ingredients**.\n",
    "- **Feature engineering** is the process through which you create features that don't natively exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame and adds new features\n",
    "def make_features(df):\n",
    "    \n",
    "    # number of ingredients\n",
    "    df['num_ingredients'] = df.ingredients.apply(len)\n",
    "    \n",
    "    # mean length of ingredient names\n",
    "    df['ingredient_length'] = df.ingredients.apply(lambda x: np.mean([len(item) for item in x]))\n",
    "    \n",
    "    # string representation of the ingredient list\n",
    "    df['ingredients_str'] = df.ingredients.astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the same features in the training data and the new data\n",
    "train = make_features(pd.read_json('../data/train.json'))\n",
    "new = make_features(pd.read_json('../data/test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>[u'romaine lettuce', u'black olives', u'grape ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>[u'plain flour', u'ground pepper', u'salt', u'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>[u'eggs', u'pepper', u'salt', u'mayonaise', u'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>[u'water', u'vegetable oil', u'wheat', u'salt']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>[u'black pepper', u'shallots', u'cornflour', u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  ingredient_length  \\\n",
       "0                9          12.000000   \n",
       "1               11          10.090909   \n",
       "2               12          10.333333   \n",
       "3                4           6.750000   \n",
       "4               20          10.100000   \n",
       "\n",
       "                                     ingredients_str  \n",
       "0  [u'romaine lettuce', u'black olives', u'grape ...  \n",
       "1  [u'plain flour', u'ground pepper', u'salt', u'...  \n",
       "2  [u'eggs', u'pepper', u'salt', u'mayonaise', u'...  \n",
       "3    [u'water', u'vegetable oil', u'wheat', u'salt']  \n",
       "4  [u'black pepper', u'shallots', u'cornflour', u...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>[u'baking powder', u'eggs', u'all-purpose flou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.272727</td>\n",
       "      <td>[u'sugar', u'egg yolks', u'corn starch', u'cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>[u'sausage links', u'fennel bulb', u'fronds', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td>21</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>[u'meat cuts', u'file powder', u'smoked sausag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td>8</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>[u'ground black pepper', u'salt', u'sausage ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  num_ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...                6   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...               11   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...                6   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...               21   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...                8   \n",
       "\n",
       "   ingredient_length                                    ingredients_str  \n",
       "0           9.333333  [u'baking powder', u'eggs', u'all-purpose flou...  \n",
       "1          10.272727  [u'sugar', u'egg yolks', u'corn starch', u'cre...  \n",
       "2           9.666667  [u'sausage links', u'fennel bulb', u'fronds', ...  \n",
       "3          12.000000  [u'meat cuts', u'file powder', u'smoked sausag...  \n",
       "4          13.000000  [u'ground black pepper', u'salt', u'sausage ca...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Using a `Pipeline` for proper cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = train.ingredients_str\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [u'romaine lettuce', u'black olives', u'grape ...\n",
       "1    [u'plain flour', u'ground pepper', u'salt', u'...\n",
       "2    [u'eggs', u'pepper', u'salt', u'mayonaise', u'...\n",
       "3      [u'water', u'vegetable oil', u'wheat', u'salt']\n",
       "4    [u'black pepper', u'shallots', u'cornflour', u...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is just a Series of strings\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace the regex pattern that is used for tokenization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(token_pattern=r\"'([a-z ]+)'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate Multinomial Naive Bayes (with the default parameters)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a pipeline of vectorization and Naive Bayes\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(vect, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvectorizer',\n",
       "  CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "          vocabulary=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proper cross-validation:**\n",
    "\n",
    "- By passing our pipeline to **`cross_val_score`**, features will be created from **`X`** (via **`CountVectorizer`**) within each fold of cross-validation.\n",
    "- This process simulates the real world, in which your out-of-sample data will contain **features that were not seen** during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73228849337901514"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate the entire pipeline\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Combining `GridSearchCV` with `Pipeline`\n",
    "\n",
    "- We use **`GridSearchCV`** to locate optimal tuning parameters by performing an \"exhaustive grid search\" of different parameter combinations, searching for the combination that has the best cross-validated accuracy.\n",
    "- By passing a **`Pipeline`** to **`GridSearchCV`** (instead of just a model), we can search tuning parameters for both the vectorizer and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multinomialnb', 'countvectorizer']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline steps are automatically assigned names by make_pipeline\n",
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': [0.5, 1]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GridSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass the pipeline (instead of the model) to GridSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'multinomialnb__alpha': [0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time the grid search\n",
    "%time grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.72439, std: 0.00472, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.5},\n",
       " mean: 0.72326, std: 0.00484, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 1},\n",
       " mean: 0.74770, std: 0.00460, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5},\n",
       " mean: 0.73229, std: 0.00552, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 1}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the score for each combination of parameters\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.747699502187\n",
      "{'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# print the single best score and parameters that produced that score\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Efficiently searching for tuning parameters using `RandomizedSearchCV`\n",
    "\n",
    "- When there are many parameters to tune, searching all possible combinations of parameter values may be **computationally infeasible**.\n",
    "- **`RandomizedSearchCV`** searches a sample of the parameter values, and you control the computational \"budget\".\n",
    "\n",
    "[RandomizedSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.stats documentation](http://docs.scipy.org/doc/scipy/reference/stats.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__min_df': [1, 2, 3],\n",
       " 'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen at 0xe7b8860>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for any continuous parameters, specify a distribution instead of a list of options\n",
    "import scipy as sp\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['countvectorizer__min_df'] = [1, 2, 3]\n",
    "param_grid['multinomialnb__alpha'] = sp.stats.uniform(scale=1)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set a random seed for sp.stats.uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# additional parameters are n_iter (number of searches) and random_state\n",
    "rand = RandomizedSearchCV(pipe, param_grid, cv=5, scoring='accuracy', n_iter=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "          fit_params={}, iid=True, n_iter=5, n_jobs=1,\n",
       "          param_distributions={'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000000E7B8860>, 'countvectorizer__min_df': [1, 2, 3]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time the randomized search\n",
    "%time rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.74986, std: 0.00494, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.417022004702574, 'countvectorizer__min_df': 2},\n",
       " mean: 0.72462, std: 0.00446, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.7203244934421581, 'countvectorizer__min_df': 1},\n",
       " mean: 0.72829, std: 0.00537, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.00011437481734488664, 'countvectorizer__min_df': 2},\n",
       " mean: 0.75137, std: 0.00438, params: {'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.30233257263183977, 'countvectorizer__min_df': 2},\n",
       " mean: 0.72233, std: 0.00450, params: {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b', 'multinomialnb__alpha': 0.14675589081711304, 'countvectorizer__min_df': 1}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751370241867\n",
      "{'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.30233257263183977, 'countvectorizer__min_df': 2}\n"
     ]
    }
   ],
   "source": [
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X_new as the ingredient text\n",
    "X_new = new.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=0.302332572632, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best model found by RandomizedSearchCV\n",
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'british', u'southern_us', u'italian', ..., u'italian',\n",
       "       u'southern_us', u'mexican'], \n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomizedSearchCV/GridSearchCV automatically refit the best model with the entire dataset, and can be used to make predictions\n",
    "new_pred_class_rand = rand.predict(X_new)\n",
    "new_pred_class_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.75342)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new_pred_class_rand}).set_index('id').to_csv('sub3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adding features to a document-term matrix (using SciPy)\n",
    "\n",
    "- So far, we've trained models on either the **document-term matrix** or the **manually created features**, but not both.\n",
    "- To train a model on both types of features, we need to **combine them into a single feature matrix**.\n",
    "- Because one of the matrices is **sparse** and the other is **dense**, the easiest way to combine them is by using SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from all of the training data\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.sparse documentation](http://docs.scipy.org/doc/scipy/reference/sparse.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of the manually created features\n",
    "X_manual = train.loc[:, ['num_ingredients', 'ingredient_length']]\n",
    "X_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sparse matrix from the DataFrame\n",
    "X_manual_sparse = sp.sparse.csr_matrix(X_manual)\n",
    "type(X_manual_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6252)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two sparse matrices\n",
    "X_dtm_manual = sp.sparse.hstack([X_dtm, X_manual_sparse])\n",
    "X_dtm_manual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This was a relatively easy process.\n",
    "- However, it does not allow us to do **proper cross-validation**, and it doesn't integrate well with the rest of the **scikit-learn workflow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Adding features to a document-term matrix (using `FeatureUnion`)\n",
    "\n",
    "- Below is an alternative process that does allow for proper cross-validation, and does integrate well with the scikit-learn workflow.\n",
    "- To use this process, we have to learn about transformers, **`FunctionTransformer`**, and **`FeatureUnion`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are \"transformers\"?\n",
    "\n",
    "Transformer objects provide a `transform` method in order to perform **data transformations**. Here are a few examples:\n",
    "\n",
    "- **`CountVectorizer`**\n",
    "    - `fit` learns the vocabulary\n",
    "    - `transform` creates a document-term matrix using the vocabulary\n",
    "- **`Imputer`**\n",
    "    - `fit` learns the value to impute\n",
    "    - `transform` fills in missing entries using the imputation value\n",
    "- **`StandardScaler`**\n",
    "    - `fit` learns the mean and scale of each feature\n",
    "    - `transform` standardizes the features using the mean and scale\n",
    "- **`HashingVectorizer`**\n",
    "    - `fit` is not used, and thus it is known as a \"stateless\" transformer\n",
    "    - `transform` creates the document-term matrix using a hash of the token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a function into a transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame returns the manually created features\n",
    "def get_manual(df):\n",
    "    return df.loc[:, ['num_ingredients', 'ingredient_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_ingredients  ingredient_length\n",
       "0                9          12.000000\n",
       "1               11          10.090909\n",
       "2               12          10.333333\n",
       "3                4           6.750000\n",
       "4               20          10.100000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_manual(train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FunctionTransformer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) (new in 0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing._function_transformer.FunctionTransformer"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a stateless transformer from the get_manual function\n",
    "get_manual_ft = FunctionTransformer(get_manual, validate=False)\n",
    "type(get_manual_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_ingredients  ingredient_length\n",
       "0                9          12.000000\n",
       "1               11          10.090909\n",
       "2               12          10.333333\n",
       "3                4           6.750000\n",
       "4               20          10.100000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute the function using the transform method\n",
    "get_manual_ft.transform(train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame returns the ingredients string\n",
    "def get_text(df):\n",
    "    return df.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [u'romaine lettuce', u'black olives', u'grape ...\n",
       "1    [u'plain flour', u'ground pepper', u'salt', u'...\n",
       "2    [u'eggs', u'pepper', u'salt', u'mayonaise', u'...\n",
       "3      [u'water', u'vegetable oil', u'wheat', u'salt']\n",
       "4    [u'black pepper', u'shallots', u'cornflour', u...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and test another transformer\n",
    "get_text_ft = FunctionTransformer(get_text, validate=False)\n",
    "get_text_ft.transform(train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining feature extraction steps\n",
    "\n",
    "- **`FeatureUnion`** applies a list of transformers in parallel to the input data (not sequentially), then **concatenates the results**.\n",
    "- This is useful for combining several feature extraction mechanisms into a single transformer.\n",
    "\n",
    "![Pipeline versus FeatureUnion](06_pipeline_versus_featureunion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_union documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_union.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from all of the training data\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is identical to a FeatureUnion with just one transformer\n",
    "union = make_union(vect)\n",
    "X_dtm = union.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try to add a second transformer to the Feature Union (what's wrong with this?)\n",
    "# union = make_union(vect, get_manual_ft)\n",
    "# X_dtm_manual = union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6252)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properly combine the transformers into a FeatureUnion\n",
    "union = make_union(make_pipeline(get_text_ft, vect), get_manual_ft)\n",
    "X_dtm_manual = union.fit_transform(train)\n",
    "X_dtm_manual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline in a FeatureUnion](06_pipeline_in_a_featureunion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71028951068529533"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly improper cross-validation\n",
    "cross_val_score(nb, X_dtm_manual, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a pipeline of the FeatureUnion and Naive Bayes\n",
    "pipe = make_pipeline(union, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71343183886118777"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properly cross-validate the entire pipeline (and pass it the entire DataFrame)\n",
    "cross_val_score(pipe, train, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to specify `Pipeline` and `FeatureUnion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reminder of how we created the pipeline\n",
    "union = make_union(make_pipeline(get_text_ft, vect), get_manual_ft)\n",
    "pipe = make_pipeline(union, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [FeatureUnion documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# duplicate the pipeline structure without using make_pipeline or make_union\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "pipe = Pipeline([\n",
    "    ('featureunion', FeatureUnion([\n",
    "            ('pipeline', Pipeline([\n",
    "                    ('functiontransformer', get_text_ft),\n",
    "                    ('countvectorizer', vect)\n",
    "                    ])),\n",
    "            ('functiontransformer', get_manual_ft)\n",
    "        ])),\n",
    "    ('multinomialnb', nb)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search of a nested `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('featureunion', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('pipeline', Pipeline(steps=[('functiontransformer', FunctionTransformer(accept_sparse=False,\n",
       "            func=<function get_text at 0x000000000E9FDDD8>, pass_y=False,\n",
       "            validate=False)), ('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'stric...         func=<function get_manual at 0x000000000E9FD128>, pass_y=False,\n",
       "            validate=False))],\n",
       "         transformer_weights=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featureunion__pipeline__countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b',\n",
       "  \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': [0.5, 1]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['featureunion__pipeline__countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline', Pipeline(steps=[('functiontransformer', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function get_text at 0x000000000E9FDDD8>, pass_y=False,\n",
       "          validate=False)), ('countvectorizer', CountVectorize...ormer_weights=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'featureunion__pipeline__countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'multinomialnb__alpha': [0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grid.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742671091668\n",
      "{'featureunion__pipeline__countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Ensembling models\n",
    "\n",
    "Rather than combining features into a single feature matrix and training a single model, we can instead create separate models and \"ensemble\" them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is ensembling?\n",
    "\n",
    "Ensemble learning (or \"ensembling\") is the process of combining several predictive models in order to produce a combined model that is **better than any individual model**.\n",
    "\n",
    "- **Regression:** average the predictions made by the individual models\n",
    "- **Classification:** let the models \"vote\" and use the most common prediction, or average the predicted probabilities\n",
    "\n",
    "For ensembling to work well, the models must have the following characteristics:\n",
    "\n",
    "- **Accurate:** they outperform the null model\n",
    "- **Independent:** their predictions are generated using different \"processes\", such as:\n",
    "    - different types of models\n",
    "    - different features\n",
    "    - different tuning parameters\n",
    "\n",
    "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when averaging the models.\n",
    "\n",
    "**Note:** There are also models that have built-in ensembling, such as Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: KNN model using only manually created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['num_ingredients', 'ingredient_length']\n",
    "X = train[feature_cols]\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use KNN with K=800\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=800, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train KNN on all of the training data\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X_new as the manually created features\n",
    "X_new = new[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944L, 20L)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities of class membership for the new data\n",
    "new_pred_prob_knn = knn.predict_proba(X_new)\n",
    "new_pred_prob_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02625,  0.0275 ,  0.01375,  0.04375,  0.03375,  0.08   ,\n",
       "        0.0175 ,  0.075  ,  0.0275 ,  0.135  ,  0.01   ,  0.075  ,\n",
       "        0.01875,  0.165  ,  0.00875,  0.0125 ,  0.1525 ,  0.025  ,\n",
       "        0.0275 ,  0.025  ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted probabilities for the first row only\n",
    "new_pred_prob_knn[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'brazilian', 0.026249999999999999),\n",
       " (u'british', 0.0275),\n",
       " (u'cajun_creole', 0.01375),\n",
       " (u'chinese', 0.043749999999999997),\n",
       " (u'filipino', 0.033750000000000002),\n",
       " (u'french', 0.080000000000000002),\n",
       " (u'greek', 0.017500000000000002),\n",
       " (u'indian', 0.074999999999999997),\n",
       " (u'irish', 0.0275),\n",
       " (u'italian', 0.13500000000000001),\n",
       " (u'jamaican', 0.01),\n",
       " (u'japanese', 0.074999999999999997),\n",
       " (u'korean', 0.018749999999999999),\n",
       " (u'mexican', 0.16500000000000001),\n",
       " (u'moroccan', 0.0087500000000000008),\n",
       " (u'russian', 0.012500000000000001),\n",
       " (u'southern_us', 0.1525),\n",
       " (u'spanish', 0.025000000000000001),\n",
       " (u'thai', 0.0275),\n",
       " (u'vietnamese', 0.025000000000000001)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display classes with probabilities\n",
    "zip(knn.classes_, new_pred_prob_knn[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted probabilities will sum to 1 for each row\n",
    "new_pred_prob_knn[0, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Naive Bayes model using only text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=0.302332572632, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best model found by RandomizedSearchCV\n",
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X_new as the ingredient text\n",
    "X_new = new.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944L, 20L)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities of class membership for the new data\n",
    "new_pred_prob_rand = rand.predict_proba(X_new)\n",
    "new_pred_prob_rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.35624509e-04,   5.10677208e-01,   5.01039760e-05,\n",
       "         7.46758455e-05,   3.64528916e-03,   1.36909784e-03,\n",
       "         4.25463842e-04,   3.16817133e-04,   1.85847350e-01,\n",
       "         3.78331630e-03,   2.67495007e-04,   5.60369424e-04,\n",
       "         4.27190054e-06,   8.85175984e-04,   8.50499605e-06,\n",
       "         3.04368393e-02,   2.60701445e-01,   3.09630257e-04,\n",
       "         1.07646647e-06,   2.45297976e-07])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted probabilities for the first row only\n",
    "new_pred_prob_rand[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling models 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01344281,  0.2690886 ,  0.00690005,  0.02191234,  0.01869764,\n",
       "        0.04068455,  0.00896273,  0.03765841,  0.10667368,  0.06939166,\n",
       "        0.00513375,  0.03778018,  0.00937714,  0.08294259,  0.00437925,\n",
       "        0.02146842,  0.20660072,  0.01265482,  0.01375054,  0.01250012])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of the predicted probabilities for the first row\n",
    "(new_pred_prob_knn[0, :] + new_pred_prob_rand[0, :]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brazilian</th>\n",
       "      <th>british</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>french</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>irish</th>\n",
       "      <th>italian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>japanese</th>\n",
       "      <th>korean</th>\n",
       "      <th>mexican</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>russian</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>thai</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.269089</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.021912</td>\n",
       "      <td>0.018698</td>\n",
       "      <td>0.040685</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>0.037658</td>\n",
       "      <td>0.106674</td>\n",
       "      <td>0.069392</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.037780</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.082943</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.206601</td>\n",
       "      <td>0.012655</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.016875</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.018132</td>\n",
       "      <td>0.023884</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>0.010629</td>\n",
       "      <td>0.070625</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>0.027501</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.066875</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.547901</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>0.013125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.041365</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.029376</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.038752</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.080630</td>\n",
       "      <td>0.025887</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.079377</td>\n",
       "      <td>0.158440</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.012502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>0.038750</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.075625</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.051875</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.038125</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.017501</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>0.640841</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.083129</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.072838</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brazilian   british  cajun_creole   chinese  filipino    french     greek  \\\n",
       "0   0.013443  0.269089      0.006900  0.021912  0.018698  0.040685  0.008963   \n",
       "1   0.008752  0.011324      0.016875  0.045000  0.018132  0.023884  0.015625   \n",
       "2   0.013158  0.009389      0.006951  0.020000  0.015010  0.041365  0.010101   \n",
       "3   0.003125  0.004375      0.533750  0.038750  0.001875  0.023125  0.006250   \n",
       "4   0.001878  0.009856      0.020097  0.021250  0.003125  0.044922  0.017501   \n",
       "\n",
       "     indian     irish   italian  jamaican  japanese    korean   mexican  \\\n",
       "0  0.037658  0.106674  0.069392  0.005134  0.037780  0.009377  0.082943   \n",
       "1  0.046250  0.010629  0.070625  0.005626  0.027501  0.021875  0.066875   \n",
       "2  0.029376  0.013372  0.408696  0.005628  0.038752  0.007500  0.080630   \n",
       "3  0.075625  0.001250  0.051875  0.011875  0.008125  0.003125  0.107500   \n",
       "4  0.013750  0.012547  0.640841  0.003752  0.007500  0.003750  0.083129   \n",
       "\n",
       "   moroccan   russian  southern_us   spanish      thai  vietnamese  \n",
       "0  0.004379  0.021468     0.206601  0.012655  0.013751    0.012500  \n",
       "1  0.008125  0.008750     0.547901  0.007500  0.025625    0.013125  \n",
       "2  0.025887  0.008240     0.079377  0.158440  0.015625    0.012502  \n",
       "3  0.029375  0.001875     0.025000  0.007500  0.038125    0.027500  \n",
       "4  0.004376  0.003135     0.072838  0.018252  0.014375    0.003125  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of the predicted probabilities for all rows\n",
    "new_pred_prob = pd.DataFrame((new_pred_prob_knn + new_pred_prob_rand) / 2, columns=knn.classes_)\n",
    "new_pred_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         british\n",
       "1     southern_us\n",
       "2         italian\n",
       "3    cajun_creole\n",
       "4         italian\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each row, find the column with the highest predicted probability\n",
    "new_pred_class = new_pred_prob.apply(np.argmax, axis=1)\n",
    "new_pred_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.75241)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new_pred_class}).set_index('id').to_csv('sub4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** [VotingClassifier](http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier) (new in 0.17) makes it easier to ensemble classifiers, though it is limited to the case in which all of the classifiers are fit to the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Locating groups of similar cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine\n",
       "brazilian       [u'ice cubes', u'club soda', u'white rum', u'l...\n",
       "british         [u'greek yogurt', u'lemon curd', u'confectione...\n",
       "cajun_creole    [u'herbs', u'lemon juice', u'fresh tomatoes', ...\n",
       "chinese         [u'low sodium soy sauce', u'fresh ginger', u'd...\n",
       "filipino        [u'eggs', u'pepper', u'salt', u'mayonaise', u'...\n",
       "french          [u'sugar', u'salt', u'fennel bulb', u'water', ...\n",
       "greek           [u'romaine lettuce', u'black olives', u'grape ...\n",
       "indian          [u'water', u'vegetable oil', u'wheat', u'salt'...\n",
       "irish           [u'cooking spray', u'salt', u'black pepper', u...\n",
       "italian         [u'sugar', u'pistachio nuts', u'white almond b...\n",
       "jamaican        [u'plain flour', u'sugar', u'butter', u'eggs',...\n",
       "japanese        [u'sirloin', u'mirin', u'yellow onion', u'low ...\n",
       "korean          [u'jasmine rice', u'garlic', u'scallions', u's...\n",
       "mexican         [u'olive oil', u'purple onion', u'fresh pineap...\n",
       "moroccan        [u'ground cloves', u'whole nutmegs', u'ground ...\n",
       "russian         [u'water', u'grits', u'mozzarella cheese', u's...\n",
       "southern_us     [u'plain flour', u'ground pepper', u'salt', u'...\n",
       "spanish         [u'olive oil', u'salt', u'medium shrimp', u'pe...\n",
       "thai            [u'sugar', u'hot chili', u'asian fish sauce', ...\n",
       "vietnamese      [u'soy sauce', u'vegetable oil', u'red bell pe...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each cuisine, combine all of the recipes into a single string\n",
    "cuisine_ingredients = train.groupby('cuisine').ingredients_str.sum()\n",
    "cuisine_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[u'ice cubes', u'club soda', u'white rum', u'lime', u'turbinado'][u'eggs', u'hearts of palm', u'cilantro', u'coconut cream', u'flax seed meal', u'kosher salt', u'jalapeno chilies', u'garlic', u'cream cheese, soften', u'coconut oil', u'lime juice', u'crushed red pepper flakes', u'ground coriander', u'pepper', u'chicken breasts', u'coconut flour', u'onions'][u'sweetened condensed milk', u'butter', u'cocoa powder'][u'lime', u'crushed ice', u'simple syrup', u'cachaca'][u'sugar', u'corn starch', u'eg\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the brazilian ingredients\n",
    "cuisine_ingredients['brazilian'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41     [u'ice cubes', u'club soda', u'white rum', u'l...\n",
       "380    [u'eggs', u'hearts of palm', u'cilantro', u'co...\n",
       "423    [u'sweetened condensed milk', u'butter', u'coc...\n",
       "509    [u'lime', u'crushed ice', u'simple syrup', u'c...\n",
       "724    [u'sugar', u'corn starch', u'egg whites', u'bo...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that they match the brazilian recipes\n",
    "train.loc[train.cuisine=='brazilian', 'ingredients_str'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3028)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from cuisine_ingredients\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "cuisine_dtm = vect.fit_transform(cuisine_ingredients)\n",
    "cuisine_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to calculate document similarity](http://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity/12128777#12128777) (Stack Overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the cosine similarity between each cuisine and all other cuisines\n",
    "from sklearn import metrics\n",
    "cuisine_similarity = []\n",
    "for idx in range(cuisine_dtm.shape[0]):\n",
    "    similarity = metrics.pairwise.linear_kernel(cuisine_dtm[idx, :], cuisine_dtm).flatten()\n",
    "    cuisine_similarity.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cuisine</th>\n",
       "      <th>brazilian</th>\n",
       "      <th>british</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>french</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>irish</th>\n",
       "      <th>italian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>japanese</th>\n",
       "      <th>korean</th>\n",
       "      <th>mexican</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>russian</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>thai</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660156</td>\n",
       "      <td>0.742322</td>\n",
       "      <td>0.580757</td>\n",
       "      <td>0.769215</td>\n",
       "      <td>0.755767</td>\n",
       "      <td>0.695686</td>\n",
       "      <td>0.687244</td>\n",
       "      <td>0.665677</td>\n",
       "      <td>0.740519</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.555601</td>\n",
       "      <td>0.571439</td>\n",
       "      <td>0.743713</td>\n",
       "      <td>0.669002</td>\n",
       "      <td>0.705931</td>\n",
       "      <td>0.743146</td>\n",
       "      <td>0.807689</td>\n",
       "      <td>0.685539</td>\n",
       "      <td>0.653800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>0.660156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591167</td>\n",
       "      <td>0.467593</td>\n",
       "      <td>0.631277</td>\n",
       "      <td>0.859299</td>\n",
       "      <td>0.562693</td>\n",
       "      <td>0.560318</td>\n",
       "      <td>0.926662</td>\n",
       "      <td>0.632588</td>\n",
       "      <td>0.661978</td>\n",
       "      <td>0.508248</td>\n",
       "      <td>0.447121</td>\n",
       "      <td>0.560398</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.909555</td>\n",
       "      <td>0.911177</td>\n",
       "      <td>0.603975</td>\n",
       "      <td>0.445473</td>\n",
       "      <td>0.478860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>0.742322</td>\n",
       "      <td>0.591167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>0.746149</td>\n",
       "      <td>0.708263</td>\n",
       "      <td>0.688395</td>\n",
       "      <td>0.618938</td>\n",
       "      <td>0.635172</td>\n",
       "      <td>0.738158</td>\n",
       "      <td>0.780895</td>\n",
       "      <td>0.532397</td>\n",
       "      <td>0.578644</td>\n",
       "      <td>0.724866</td>\n",
       "      <td>0.649826</td>\n",
       "      <td>0.657667</td>\n",
       "      <td>0.747479</td>\n",
       "      <td>0.803631</td>\n",
       "      <td>0.590103</td>\n",
       "      <td>0.605223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.580757</td>\n",
       "      <td>0.467593</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839802</td>\n",
       "      <td>0.540009</td>\n",
       "      <td>0.496090</td>\n",
       "      <td>0.553515</td>\n",
       "      <td>0.460728</td>\n",
       "      <td>0.555503</td>\n",
       "      <td>0.635953</td>\n",
       "      <td>0.835586</td>\n",
       "      <td>0.866827</td>\n",
       "      <td>0.561824</td>\n",
       "      <td>0.505653</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.558511</td>\n",
       "      <td>0.603523</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.817003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filipino</th>\n",
       "      <td>0.769215</td>\n",
       "      <td>0.631277</td>\n",
       "      <td>0.746149</td>\n",
       "      <td>0.839802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682372</td>\n",
       "      <td>0.607433</td>\n",
       "      <td>0.655896</td>\n",
       "      <td>0.640979</td>\n",
       "      <td>0.670621</td>\n",
       "      <td>0.792723</td>\n",
       "      <td>0.748554</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.678285</td>\n",
       "      <td>0.614970</td>\n",
       "      <td>0.696845</td>\n",
       "      <td>0.720363</td>\n",
       "      <td>0.727401</td>\n",
       "      <td>0.741510</td>\n",
       "      <td>0.806831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>0.755767</td>\n",
       "      <td>0.859299</td>\n",
       "      <td>0.708263</td>\n",
       "      <td>0.540009</td>\n",
       "      <td>0.682372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759303</td>\n",
       "      <td>0.624355</td>\n",
       "      <td>0.836959</td>\n",
       "      <td>0.834680</td>\n",
       "      <td>0.722627</td>\n",
       "      <td>0.539835</td>\n",
       "      <td>0.501789</td>\n",
       "      <td>0.666329</td>\n",
       "      <td>0.684843</td>\n",
       "      <td>0.880922</td>\n",
       "      <td>0.861419</td>\n",
       "      <td>0.816989</td>\n",
       "      <td>0.547923</td>\n",
       "      <td>0.570485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>0.695686</td>\n",
       "      <td>0.562693</td>\n",
       "      <td>0.688395</td>\n",
       "      <td>0.496090</td>\n",
       "      <td>0.607433</td>\n",
       "      <td>0.759303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640285</td>\n",
       "      <td>0.583655</td>\n",
       "      <td>0.859268</td>\n",
       "      <td>0.681278</td>\n",
       "      <td>0.469471</td>\n",
       "      <td>0.479832</td>\n",
       "      <td>0.696638</td>\n",
       "      <td>0.769405</td>\n",
       "      <td>0.649402</td>\n",
       "      <td>0.641235</td>\n",
       "      <td>0.837435</td>\n",
       "      <td>0.519005</td>\n",
       "      <td>0.538680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>0.687244</td>\n",
       "      <td>0.560318</td>\n",
       "      <td>0.618938</td>\n",
       "      <td>0.553515</td>\n",
       "      <td>0.655896</td>\n",
       "      <td>0.624355</td>\n",
       "      <td>0.640285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577297</td>\n",
       "      <td>0.616204</td>\n",
       "      <td>0.734893</td>\n",
       "      <td>0.567991</td>\n",
       "      <td>0.538822</td>\n",
       "      <td>0.708576</td>\n",
       "      <td>0.795278</td>\n",
       "      <td>0.607321</td>\n",
       "      <td>0.617247</td>\n",
       "      <td>0.678842</td>\n",
       "      <td>0.627444</td>\n",
       "      <td>0.605132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>0.665677</td>\n",
       "      <td>0.926662</td>\n",
       "      <td>0.635172</td>\n",
       "      <td>0.460728</td>\n",
       "      <td>0.640979</td>\n",
       "      <td>0.836959</td>\n",
       "      <td>0.583655</td>\n",
       "      <td>0.577297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649873</td>\n",
       "      <td>0.680880</td>\n",
       "      <td>0.494742</td>\n",
       "      <td>0.458775</td>\n",
       "      <td>0.591703</td>\n",
       "      <td>0.563278</td>\n",
       "      <td>0.892391</td>\n",
       "      <td>0.902821</td>\n",
       "      <td>0.630912</td>\n",
       "      <td>0.449910</td>\n",
       "      <td>0.481697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>0.740519</td>\n",
       "      <td>0.632588</td>\n",
       "      <td>0.738158</td>\n",
       "      <td>0.555503</td>\n",
       "      <td>0.670621</td>\n",
       "      <td>0.834680</td>\n",
       "      <td>0.859268</td>\n",
       "      <td>0.616204</td>\n",
       "      <td>0.649873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695762</td>\n",
       "      <td>0.510283</td>\n",
       "      <td>0.522563</td>\n",
       "      <td>0.733954</td>\n",
       "      <td>0.709824</td>\n",
       "      <td>0.697503</td>\n",
       "      <td>0.718946</td>\n",
       "      <td>0.858160</td>\n",
       "      <td>0.555086</td>\n",
       "      <td>0.571094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamaican</th>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.661978</td>\n",
       "      <td>0.780895</td>\n",
       "      <td>0.635953</td>\n",
       "      <td>0.792723</td>\n",
       "      <td>0.722627</td>\n",
       "      <td>0.681278</td>\n",
       "      <td>0.734893</td>\n",
       "      <td>0.680880</td>\n",
       "      <td>0.695762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.584688</td>\n",
       "      <td>0.609204</td>\n",
       "      <td>0.731839</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.752855</td>\n",
       "      <td>0.751666</td>\n",
       "      <td>0.650899</td>\n",
       "      <td>0.664173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>0.555601</td>\n",
       "      <td>0.508248</td>\n",
       "      <td>0.532397</td>\n",
       "      <td>0.835586</td>\n",
       "      <td>0.748554</td>\n",
       "      <td>0.539835</td>\n",
       "      <td>0.469471</td>\n",
       "      <td>0.567991</td>\n",
       "      <td>0.494742</td>\n",
       "      <td>0.510283</td>\n",
       "      <td>0.584688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819824</td>\n",
       "      <td>0.506529</td>\n",
       "      <td>0.477408</td>\n",
       "      <td>0.557163</td>\n",
       "      <td>0.554021</td>\n",
       "      <td>0.547334</td>\n",
       "      <td>0.682605</td>\n",
       "      <td>0.738409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>0.571439</td>\n",
       "      <td>0.447121</td>\n",
       "      <td>0.578644</td>\n",
       "      <td>0.866827</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.501789</td>\n",
       "      <td>0.479832</td>\n",
       "      <td>0.538822</td>\n",
       "      <td>0.458775</td>\n",
       "      <td>0.522563</td>\n",
       "      <td>0.609204</td>\n",
       "      <td>0.819824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516448</td>\n",
       "      <td>0.477953</td>\n",
       "      <td>0.517565</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.582963</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.747117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican</th>\n",
       "      <td>0.743713</td>\n",
       "      <td>0.560398</td>\n",
       "      <td>0.724866</td>\n",
       "      <td>0.561824</td>\n",
       "      <td>0.678285</td>\n",
       "      <td>0.666329</td>\n",
       "      <td>0.696638</td>\n",
       "      <td>0.708576</td>\n",
       "      <td>0.591703</td>\n",
       "      <td>0.733954</td>\n",
       "      <td>0.731839</td>\n",
       "      <td>0.506529</td>\n",
       "      <td>0.516448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697416</td>\n",
       "      <td>0.630440</td>\n",
       "      <td>0.691391</td>\n",
       "      <td>0.739852</td>\n",
       "      <td>0.617611</td>\n",
       "      <td>0.623522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moroccan</th>\n",
       "      <td>0.669002</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.649826</td>\n",
       "      <td>0.505653</td>\n",
       "      <td>0.614970</td>\n",
       "      <td>0.684843</td>\n",
       "      <td>0.769405</td>\n",
       "      <td>0.795278</td>\n",
       "      <td>0.563278</td>\n",
       "      <td>0.709824</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.477408</td>\n",
       "      <td>0.477953</td>\n",
       "      <td>0.697416</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608238</td>\n",
       "      <td>0.605945</td>\n",
       "      <td>0.784603</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.553366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>russian</th>\n",
       "      <td>0.705931</td>\n",
       "      <td>0.909555</td>\n",
       "      <td>0.657667</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.696845</td>\n",
       "      <td>0.880922</td>\n",
       "      <td>0.649402</td>\n",
       "      <td>0.607321</td>\n",
       "      <td>0.892391</td>\n",
       "      <td>0.697503</td>\n",
       "      <td>0.684341</td>\n",
       "      <td>0.557163</td>\n",
       "      <td>0.517565</td>\n",
       "      <td>0.630440</td>\n",
       "      <td>0.608238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877742</td>\n",
       "      <td>0.702654</td>\n",
       "      <td>0.494228</td>\n",
       "      <td>0.539003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southern_us</th>\n",
       "      <td>0.743146</td>\n",
       "      <td>0.911177</td>\n",
       "      <td>0.747479</td>\n",
       "      <td>0.558511</td>\n",
       "      <td>0.720363</td>\n",
       "      <td>0.861419</td>\n",
       "      <td>0.641235</td>\n",
       "      <td>0.617247</td>\n",
       "      <td>0.902821</td>\n",
       "      <td>0.718946</td>\n",
       "      <td>0.752855</td>\n",
       "      <td>0.554021</td>\n",
       "      <td>0.516808</td>\n",
       "      <td>0.691391</td>\n",
       "      <td>0.605945</td>\n",
       "      <td>0.877742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707764</td>\n",
       "      <td>0.536960</td>\n",
       "      <td>0.562356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>0.807689</td>\n",
       "      <td>0.603975</td>\n",
       "      <td>0.803631</td>\n",
       "      <td>0.603523</td>\n",
       "      <td>0.727401</td>\n",
       "      <td>0.816989</td>\n",
       "      <td>0.837435</td>\n",
       "      <td>0.678842</td>\n",
       "      <td>0.630912</td>\n",
       "      <td>0.858160</td>\n",
       "      <td>0.751666</td>\n",
       "      <td>0.547334</td>\n",
       "      <td>0.582963</td>\n",
       "      <td>0.739852</td>\n",
       "      <td>0.784603</td>\n",
       "      <td>0.702654</td>\n",
       "      <td>0.707764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606197</td>\n",
       "      <td>0.614199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>0.685539</td>\n",
       "      <td>0.445473</td>\n",
       "      <td>0.590103</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.741510</td>\n",
       "      <td>0.547923</td>\n",
       "      <td>0.519005</td>\n",
       "      <td>0.627444</td>\n",
       "      <td>0.449910</td>\n",
       "      <td>0.555086</td>\n",
       "      <td>0.650899</td>\n",
       "      <td>0.682605</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.617611</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.494228</td>\n",
       "      <td>0.536960</td>\n",
       "      <td>0.606197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vietnamese</th>\n",
       "      <td>0.653800</td>\n",
       "      <td>0.478860</td>\n",
       "      <td>0.605223</td>\n",
       "      <td>0.817003</td>\n",
       "      <td>0.806831</td>\n",
       "      <td>0.570485</td>\n",
       "      <td>0.538680</td>\n",
       "      <td>0.605132</td>\n",
       "      <td>0.481697</td>\n",
       "      <td>0.571094</td>\n",
       "      <td>0.664173</td>\n",
       "      <td>0.738409</td>\n",
       "      <td>0.747117</td>\n",
       "      <td>0.623522</td>\n",
       "      <td>0.553366</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>0.562356</td>\n",
       "      <td>0.614199</td>\n",
       "      <td>0.914983</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cuisine       brazilian   british  cajun_creole   chinese  filipino    french  \\\n",
       "cuisine                                                                         \n",
       "brazilian      1.000000  0.660156      0.742322  0.580757  0.769215  0.755767   \n",
       "british        0.660156  1.000000      0.591167  0.467593  0.631277  0.859299   \n",
       "cajun_creole   0.742322  0.591167      1.000000  0.605581  0.746149  0.708263   \n",
       "chinese        0.580757  0.467593      0.605581  1.000000  0.839802  0.540009   \n",
       "filipino       0.769215  0.631277      0.746149  0.839802  1.000000  0.682372   \n",
       "french         0.755767  0.859299      0.708263  0.540009  0.682372  1.000000   \n",
       "greek          0.695686  0.562693      0.688395  0.496090  0.607433  0.759303   \n",
       "indian         0.687244  0.560318      0.618938  0.553515  0.655896  0.624355   \n",
       "irish          0.665677  0.926662      0.635172  0.460728  0.640979  0.836959   \n",
       "italian        0.740519  0.632588      0.738158  0.555503  0.670621  0.834680   \n",
       "jamaican       0.778320  0.661978      0.780895  0.635953  0.792723  0.722627   \n",
       "japanese       0.555601  0.508248      0.532397  0.835586  0.748554  0.539835   \n",
       "korean         0.571439  0.447121      0.578644  0.866827  0.782623  0.501789   \n",
       "mexican        0.743713  0.560398      0.724866  0.561824  0.678285  0.666329   \n",
       "moroccan       0.669002  0.543230      0.649826  0.505653  0.614970  0.684843   \n",
       "russian        0.705931  0.909555      0.657667  0.521739  0.696845  0.880922   \n",
       "southern_us    0.743146  0.911177      0.747479  0.558511  0.720363  0.861419   \n",
       "spanish        0.807689  0.603975      0.803631  0.603523  0.727401  0.816989   \n",
       "thai           0.685539  0.445473      0.590103  0.755814  0.741510  0.547923   \n",
       "vietnamese     0.653800  0.478860      0.605223  0.817003  0.806831  0.570485   \n",
       "\n",
       "cuisine          greek    indian     irish   italian  jamaican  japanese  \\\n",
       "cuisine                                                                    \n",
       "brazilian     0.695686  0.687244  0.665677  0.740519  0.778320  0.555601   \n",
       "british       0.562693  0.560318  0.926662  0.632588  0.661978  0.508248   \n",
       "cajun_creole  0.688395  0.618938  0.635172  0.738158  0.780895  0.532397   \n",
       "chinese       0.496090  0.553515  0.460728  0.555503  0.635953  0.835586   \n",
       "filipino      0.607433  0.655896  0.640979  0.670621  0.792723  0.748554   \n",
       "french        0.759303  0.624355  0.836959  0.834680  0.722627  0.539835   \n",
       "greek         1.000000  0.640285  0.583655  0.859268  0.681278  0.469471   \n",
       "indian        0.640285  1.000000  0.577297  0.616204  0.734893  0.567991   \n",
       "irish         0.583655  0.577297  1.000000  0.649873  0.680880  0.494742   \n",
       "italian       0.859268  0.616204  0.649873  1.000000  0.695762  0.510283   \n",
       "jamaican      0.681278  0.734893  0.680880  0.695762  1.000000  0.584688   \n",
       "japanese      0.469471  0.567991  0.494742  0.510283  0.584688  1.000000   \n",
       "korean        0.479832  0.538822  0.458775  0.522563  0.609204  0.819824   \n",
       "mexican       0.696638  0.708576  0.591703  0.733954  0.731839  0.506529   \n",
       "moroccan      0.769405  0.795278  0.563278  0.709824  0.757450  0.477408   \n",
       "russian       0.649402  0.607321  0.892391  0.697503  0.684341  0.557163   \n",
       "southern_us   0.641235  0.617247  0.902821  0.718946  0.752855  0.554021   \n",
       "spanish       0.837435  0.678842  0.630912  0.858160  0.751666  0.547334   \n",
       "thai          0.519005  0.627444  0.449910  0.555086  0.650899  0.682605   \n",
       "vietnamese    0.538680  0.605132  0.481697  0.571094  0.664173  0.738409   \n",
       "\n",
       "cuisine         korean   mexican  moroccan   russian  southern_us   spanish  \\\n",
       "cuisine                                                                       \n",
       "brazilian     0.571439  0.743713  0.669002  0.705931     0.743146  0.807689   \n",
       "british       0.447121  0.560398  0.543230  0.909555     0.911177  0.603975   \n",
       "cajun_creole  0.578644  0.724866  0.649826  0.657667     0.747479  0.803631   \n",
       "chinese       0.866827  0.561824  0.505653  0.521739     0.558511  0.603523   \n",
       "filipino      0.782623  0.678285  0.614970  0.696845     0.720363  0.727401   \n",
       "french        0.501789  0.666329  0.684843  0.880922     0.861419  0.816989   \n",
       "greek         0.479832  0.696638  0.769405  0.649402     0.641235  0.837435   \n",
       "indian        0.538822  0.708576  0.795278  0.607321     0.617247  0.678842   \n",
       "irish         0.458775  0.591703  0.563278  0.892391     0.902821  0.630912   \n",
       "italian       0.522563  0.733954  0.709824  0.697503     0.718946  0.858160   \n",
       "jamaican      0.609204  0.731839  0.757450  0.684341     0.752855  0.751666   \n",
       "japanese      0.819824  0.506529  0.477408  0.557163     0.554021  0.547334   \n",
       "korean        1.000000  0.516448  0.477953  0.517565     0.516808  0.582963   \n",
       "mexican       0.516448  1.000000  0.697416  0.630440     0.691391  0.739852   \n",
       "moroccan      0.477953  0.697416  1.000000  0.608238     0.605945  0.784603   \n",
       "russian       0.517565  0.630440  0.608238  1.000000     0.877742  0.702654   \n",
       "southern_us   0.516808  0.691391  0.605945  0.877742     1.000000  0.707764   \n",
       "spanish       0.582963  0.739852  0.784603  0.702654     0.707764  1.000000   \n",
       "thai          0.671053  0.617611  0.533128  0.494228     0.536960  0.606197   \n",
       "vietnamese    0.747117  0.623522  0.553366  0.539003     0.562356  0.614199   \n",
       "\n",
       "cuisine           thai  vietnamese  \n",
       "cuisine                             \n",
       "brazilian     0.685539    0.653800  \n",
       "british       0.445473    0.478860  \n",
       "cajun_creole  0.590103    0.605223  \n",
       "chinese       0.755814    0.817003  \n",
       "filipino      0.741510    0.806831  \n",
       "french        0.547923    0.570485  \n",
       "greek         0.519005    0.538680  \n",
       "indian        0.627444    0.605132  \n",
       "irish         0.449910    0.481697  \n",
       "italian       0.555086    0.571094  \n",
       "jamaican      0.650899    0.664173  \n",
       "japanese      0.682605    0.738409  \n",
       "korean        0.671053    0.747117  \n",
       "mexican       0.617611    0.623522  \n",
       "moroccan      0.533128    0.553366  \n",
       "russian       0.494228    0.539003  \n",
       "southern_us   0.536960    0.562356  \n",
       "spanish       0.606197    0.614199  \n",
       "thai          1.000000    0.914983  \n",
       "vietnamese    0.914983    1.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the results to a DataFrame\n",
    "cuisine_list = cuisine_ingredients.index\n",
    "cuisine_similarity = pd.DataFrame(cuisine_similarity, index=cuisine_list, columns=cuisine_list)\n",
    "cuisine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16cd5ef0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAGUCAYAAAA/N/saAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16cd5860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the similarities as a heatmap\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.heatmap(cuisine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hand-selected cuisine groups\n",
    "group_1 = ['chinese', 'filipino', 'japanese', 'korean', 'thai', 'vietnamese']\n",
    "group_2 = ['british', 'french', 'irish', 'russian', 'southern_us']\n",
    "group_3 = ['greek', 'italian', 'moroccan', 'spanish']\n",
    "group_4 = ['brazilian', 'cajun_creole', 'indian', 'jamaican', 'mexican']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Model stacking\n",
    "\n",
    "- The term \"model stacking\" is used any time there are **multiple \"levels\" of models**, in which the outputs from one level are used as inputs to another level.\n",
    "- In this case, we will create one model that predicts the **cuisine group** for a recipe. Within each of the four groups, we will create another model that predicts the actual **cuisine**.\n",
    "- Our theory is that each of these five models may need to be **tuned differently** for maximum accuracy, but will ultimately result in a process that is more accurate than a single-level model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazilian': 4,\n",
       " 'british': 2,\n",
       " 'cajun_creole': 4,\n",
       " 'chinese': 1,\n",
       " 'filipino': 1,\n",
       " 'french': 2,\n",
       " 'greek': 3,\n",
       " 'indian': 4,\n",
       " 'irish': 2,\n",
       " 'italian': 3,\n",
       " 'jamaican': 4,\n",
       " 'japanese': 1,\n",
       " 'korean': 1,\n",
       " 'mexican': 4,\n",
       " 'moroccan': 3,\n",
       " 'russian': 2,\n",
       " 'southern_us': 2,\n",
       " 'spanish': 3,\n",
       " 'thai': 1,\n",
       " 'vietnamese': 1}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary that maps each cuisine to its group number\n",
    "cuisines = group_1 + group_2 + group_3 + group_4\n",
    "group_numbers = [1]*len(group_1) + [2]*len(group_2) + [3]*len(group_3) + [4]*len(group_4)\n",
    "cuisine_to_group = dict(zip(cuisines, group_numbers))\n",
    "cuisine_to_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>[u'romaine lettuce', u'black olives', u'grape ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>[u'plain flour', u'ground pepper', u'salt', u'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>[u'eggs', u'pepper', u'salt', u'mayonaise', u'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>[u'water', u'vegetable oil', u'wheat', u'salt']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>[u'black pepper', u'shallots', u'cornflour', u...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  ingredient_length  \\\n",
       "0                9          12.000000   \n",
       "1               11          10.090909   \n",
       "2               12          10.333333   \n",
       "3                4           6.750000   \n",
       "4               20          10.100000   \n",
       "\n",
       "                                     ingredients_str  group  \n",
       "0  [u'romaine lettuce', u'black olives', u'grape ...      3  \n",
       "1  [u'plain flour', u'ground pepper', u'salt', u'...      2  \n",
       "2  [u'eggs', u'pepper', u'salt', u'mayonaise', u'...      1  \n",
       "3    [u'water', u'vegetable oil', u'wheat', u'salt']      4  \n",
       "4  [u'black pepper', u'shallots', u'cornflour', u...      4  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the cuisines to their group numbers\n",
    "train['group'] = train.cuisine.map(cuisine_to_group)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that all recipes were assigned a cuisine group\n",
    "train.group.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82765137960555035"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the cross-validated accuracy of using text to predict cuisine group\n",
    "X = train.ingredients_str\n",
    "y = train.group\n",
    "pipe_main = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "cross_val_score(pipe_main, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define an X and y for each cuisine group\n",
    "X1 = train.loc[train.group==1, 'ingredients_str']\n",
    "y1 = train.loc[train.group==1, 'cuisine']\n",
    "X2 = train.loc[train.group==2, 'ingredients_str']\n",
    "y2 = train.loc[train.group==2, 'cuisine']\n",
    "X3 = train.loc[train.group==3, 'ingredients_str']\n",
    "y3 = train.loc[train.group==3, 'cuisine']\n",
    "X4 = train.loc[train.group==4, 'ingredients_str']\n",
    "y4 = train.loc[train.group==4, 'cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a pipeline for each cuisine group\n",
    "pipe_1 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_2 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_3 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_4 = make_pipeline(CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769054289191\n",
      "0.757672844551\n",
      "0.869907044834\n",
      "0.904089986908\n"
     ]
    }
   ],
   "source": [
    "# within each cuisine group, calculate the cross-validated accuracy of using text to predict cuisine\n",
    "print(cross_val_score(pipe_1, X1, y1, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_2, X2, y2, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_3, X3, y3, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_4, X4, y4, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Ideally, each of the five pipelines should be **individually tuned** from start to finish, including feature engineering, model selection, and parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit each pipeline with the relevant X and y\n",
    "pipe_main.fit(X, y)\n",
    "pipe_1.fit(X1, y1)\n",
    "pipe_2.fit(X2, y2)\n",
    "pipe_3.fit(X3, y3)\n",
    "pipe_4.fit(X4, y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, ..., 3, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the new data, first make cuisine group predictions\n",
    "X_new = new.ingredients_str\n",
    "new_pred_group = pipe_main.predict(X_new)\n",
    "new_pred_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'chinese' u'japanese' u'vietnamese' ..., u'chinese' u'chinese'\n",
      " u'vietnamese']\n",
      "[u'british' u'southern_us' u'southern_us' ..., u'southern_us' u'french'\n",
      " u'french']\n",
      "[u'spanish' u'italian' u'spanish' ..., u'italian' u'italian' u'italian']\n",
      "[u'cajun_creole' u'mexican' u'indian' ..., u'mexican' u'cajun_creole'\n",
      " u'mexican']\n"
     ]
    }
   ],
   "source": [
    "# then within each predicted cuisine group, make cuisine predictions\n",
    "new_pred_class_1 = pipe_1.predict(X_new[new_pred_group==1])\n",
    "new_pred_class_2 = pipe_2.predict(X_new[new_pred_group==2])\n",
    "new_pred_class_3 = pipe_3.predict(X_new[new_pred_group==3])\n",
    "new_pred_class_4 = pipe_4.predict(X_new[new_pred_group==4])\n",
    "print(new_pred_class_1)\n",
    "print(new_pred_class_2)\n",
    "print(new_pred_class_3)\n",
    "print(new_pred_class_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add the cuisine predictions to the DataFrame of new data\n",
    "new.loc[new_pred_group==1, 'pred_class'] = new_pred_class_1\n",
    "new.loc[new_pred_group==2, 'pred_class'] = new_pred_class_2\n",
    "new.loc[new_pred_group==3, 'pred_class'] = new_pred_class_3\n",
    "new.loc[new_pred_group==4, 'pred_class'] = new_pred_class_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>[u'baking powder', u'eggs', u'all-purpose flou...</td>\n",
       "      <td>british</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.272727</td>\n",
       "      <td>[u'sugar', u'egg yolks', u'corn starch', u'cre...</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>[u'sausage links', u'fennel bulb', u'fronds', ...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td>21</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>[u'meat cuts', u'file powder', u'smoked sausag...</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td>8</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>[u'ground black pepper', u'salt', u'sausage ca...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  num_ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...                6   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...               11   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...                6   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...               21   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...                8   \n",
       "\n",
       "   ingredient_length                                    ingredients_str  \\\n",
       "0           9.333333  [u'baking powder', u'eggs', u'all-purpose flou...   \n",
       "1          10.272727  [u'sugar', u'egg yolks', u'corn starch', u'cre...   \n",
       "2           9.666667  [u'sausage links', u'fennel bulb', u'fronds', ...   \n",
       "3          12.000000  [u'meat cuts', u'file powder', u'smoked sausag...   \n",
       "4          13.000000  [u'ground black pepper', u'salt', u'sausage ca...   \n",
       "\n",
       "     pred_class  \n",
       "0       british  \n",
       "1   southern_us  \n",
       "2       spanish  \n",
       "3  cajun_creole  \n",
       "4       italian  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.70475)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new.pred_class}).set_index('id').to_csv('sub5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
